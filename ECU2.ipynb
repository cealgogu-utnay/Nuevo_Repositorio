{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN5/qcj4xrvZagLEPLgvfNw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cealgogu-utnay/Nuevo_Repositorio/blob/main/ECU2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03zmp3sHOUYc"
      },
      "outputs": [],
      "source": [
        "!uv pip install -q --system numba-cuda==0.4.0\n",
        "import numpy as np\n",
        "\n",
        "import time\n",
        "import os\n",
        "\n",
        "# Enable the CUDA simulator. This MUST be set BEFORE numba imports or kernel definitions.\n",
        "os.environ[\"NUMBA_ENABLE_CUDASIM\"] = \"1\"\n",
        "from numba import cuda\n",
        "from numba import config\n",
        "\n",
        "# --- Configuration & Data Preparation ---\n",
        "\n",
        "config.CUDA_ENABLE_PYNVJITLINK = 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare character data (ASCII values for A-H, 8 characters total)\n",
        "characters = ['A', 'B', 'C', 'D','E', 'F','G', 'H']\n",
        "data =np.array([ord(c) for c in characters], dtype=np.uint8)\n",
        "data_size = len(data) # 8 elements\n",
        "# ---- 1D Kernel Definition (using, gidx, bidx, tidx) ---\n",
        "\n",
        "@cuda.jit\n",
        "def kernel_1d_dims(arr):\n",
        "  #gidx: Global 1D index (Thread ID in the entire grid)\n",
        "  gidx = cuda.grid(1)\n",
        "\n",
        "  # bidx: Block ID (Block index in the grid)\n",
        "  bidx = cuda.blockIdx.x\n",
        "  # tidx: Thread ID (Thread index within the block)\n",
        "  tidx =cuda.threadIdx.x\n",
        "\n",
        "  if gidx < arr.size:\n",
        "    # Standar Python print works via the simulator\n",
        "     print(f\"BID: {bidx}, TID: {tidx}, GID: {gidx}, Char: {chr(arr[gidx])}\")\n",
        "# =======================================\n",
        "# Example 1: 1 Block, 8 Threads per Block\n",
        "# ========================================\n",
        "# un block no puede exceder 1024 threads (hilos)\n",
        "blocks_per_grid_ex1 = 8\n",
        "threads_per_block_ex1 = 1\n",
        "# Total threads = 1 * 8 = 8\n",
        "#blocks_per_grid_ex1 = (1000, 60, 60) = 10,000 blocks, para Y y Z lo maximo seria 64\n",
        "#threads_per_block_ex1 = (32, 32, 1) = 1,024\n",
        "# Total threads = 1,024,000 * 65,536 * 65,536 =\n",
        "\n",
        "# X = 2^(32) - 1 threads limit, X = 102,400 (check)\n",
        "# Y = 65,536 - 1 threads limit, Y = 102,400 (check)\n",
        "# Z = 65,536 - 1 threads limit, Z = 102,400 (check)\n",
        "\n",
        "kernel_1d_dims[blocks_per_grid_ex1, threads_per_block_ex1](data)\n",
        "cuda.synchronize()\n"
      ],
      "metadata": {
        "id": "sD7zkQtQPoHD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "600c622f-2f90-4ac4-f0f2-fcaad6941a7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BID: 0, TID: 0, GID: 0, Char: A\n",
            "BID: 1, TID: 0, GID: 1, Char: B\n",
            "BID: 2, TID: 0, GID: 2, Char: C\n",
            "BID: 3, TID: 0, GID: 3, Char: D\n",
            "BID: 4, TID: 0, GID: 4, Char: E\n",
            "BID: 5, TID: 0, GID: 5, Char: F\n",
            "BID: 6, TID: 0, GID: 6, Char: G\n",
            "BID: 7, TID: 0, GID: 7, Char: H\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================\n",
        "# Example 2: 2 Blocks, 4 Threads per Block\n",
        "# ==============================================================\n",
        "\n",
        "blocks_per_grid_ex2 = 2\n",
        "threads_per_block_ex2 = 4\n",
        "# Total threads = 2 * 4 = 8\n",
        "\n",
        "kernel_1d_dims[blocks_per_grid_ex2, threads_per_block_ex2](data)\n",
        "cuda.synchronize()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHGowQdITIDy",
        "outputId": "874288c5-0e64-4f15-db82-e0b115547b07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BID: 0, TID: 0, GID: 0, Char: A\n",
            "BID: 0, TID: 1, GID: 1, Char: B\n",
            "BID: 0, TID: 2, GID: 2, Char: C\n",
            "BID: 0, TID: 3, GID: 3, Char: D\n",
            "BID: 1, TID: 0, GID: 4, Char: E\n",
            "BID: 1, TID: 1, GID: 5, Char: F\n",
            "BID: 1, TID: 2, GID: 6, Char: G\n",
            "BID: 1, TID: 3, GID: 7, Char: H\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@cuda.jit\n",
        "def whoami():\n",
        "    # Compute block id in a 3D grid\n",
        "    block_id = (\n",
        "        cuda.blockIdx.x +\n",
        "        cuda.blockIdx.y * cuda.gridDim.x +\n",
        "        cuda.gridDim.x * cuda.gridDim.y\n",
        "    )\n",
        "\n",
        "    # Threads per block\n",
        "    threads_per_block = (\n",
        "        cuda.blockDim.x * cuda.blockDim.y\n",
        "    )\n",
        "\n",
        "    # Offset of this block\n",
        "    block_offset = block_id * threads_per_block\n",
        "\n",
        "    # Compute thread id inside block\n",
        "    thread_offset = (\n",
        "        cuda.threadIdx.x +\n",
        "        cuda.threadIdx.y * cuda.blockDim.x +\n",
        "        cuda.blockDim.x * cuda.blockDim.y\n",
        "    )\n",
        "\n",
        "    # Global thread id across all blocks\n",
        "    global_id = block_offset + thread_offset\n",
        "\n",
        "\n",
        "    print(f\"{global_id:03d} | Block[x, y, z]({cuda.blockIdx.x} {cuda.blockIdx.y}) = {block_id:3d} | \"\n",
        "          f\"Thread[x, y] ({cuda.threadIdx.x} {cuda.threadIdx.y} ) = {thread_offset:3d} BlockDim.x {cuda.blockDim.x} BlockDim.y {cuda.blockDim.y} GridDim.x {cuda.gridDim.x} GridDim.y {cuda.gridDim.y}\")\n",
        "\n",
        "\n",
        "b_x, b_y, b_z = 2, 2, 1\n",
        "t_x, t_y, t_z = 4, 1, 1\n",
        "\n",
        "blocks_per_grid = (b_x, b_y, b_z)\n",
        "threads_per_block = (t_x, t_y, t_z)\n",
        "\n",
        "total_blocks = b_x * b_y * b_z\n",
        "total_threads = t_x * t_y * t_z\n",
        "print(f\"{total_blocks} blocks/grid\")\n",
        "print(f\"{total_threads} threads/block\")\n",
        "print(f\"{total_blocks * total_threads} total threads\\n\")\n",
        "\n",
        "# Launch kernel\n",
        "whoami[blocks_per_grid, threads_per_block]()\n",
        "\n",
        "# Wait for GPU to finish (like cudaDeviceSynchronize)\n",
        "cuda.synchronize()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3FV67cbr75m",
        "outputId": "8e0cbd04-5bd8-499b-8eb4-651f28f25d03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 blocks/grid\n",
            "4 threads/block\n",
            "16 total threads\n",
            "\n",
            "020 | Block[x, y, z](0 0) =   4 | Thread[x, y] (0 0 ) =   4 BlockDim.x 4 BlockDim.y 1 GridDim.x 2 GridDim.y 2\n",
            "021 | Block[x, y, z](0 0) =   4 | Thread[x, y] (1 0 ) =   5 BlockDim.x 4 BlockDim.y 1 GridDim.x 2 GridDim.y 2\n",
            "022 | Block[x, y, z](0 0) =   4 | Thread[x, y] (2 0 ) =   6 BlockDim.x 4 BlockDim.y 1 GridDim.x 2 GridDim.y 2\n",
            "023 | Block[x, y, z](0 0) =   4 | Thread[x, y] (3 0 ) =   7 BlockDim.x 4 BlockDim.y 1 GridDim.x 2 GridDim.y 2\n",
            "028 | Block[x, y, z](0 1) =   6 | Thread[x, y] (0 0 ) =   4 BlockDim.x 4 BlockDim.y 1 GridDim.x 2 GridDim.y 2\n",
            "029 | Block[x, y, z](0 1) =   6 | Thread[x, y] (1 0 ) =   5 BlockDim.x 4 BlockDim.y 1 GridDim.x 2 GridDim.y 2\n",
            "030 | Block[x, y, z](0 1) =   6 | Thread[x, y] (2 0 ) =   6 BlockDim.x 4 BlockDim.y 1 GridDim.x 2 GridDim.y 2\n",
            "031 | Block[x, y, z](0 1) =   6 | Thread[x, y] (3 0 ) =   7 BlockDim.x 4 BlockDim.y 1 GridDim.x 2 GridDim.y 2\n",
            "024 | Block[x, y, z](1 0) =   5 | Thread[x, y] (0 0 ) =   4 BlockDim.x 4 BlockDim.y 1 GridDim.x 2 GridDim.y 2\n",
            "025 | Block[x, y, z](1 0) =   5 | Thread[x, y] (1 0 ) =   5 BlockDim.x 4 BlockDim.y 1 GridDim.x 2 GridDim.y 2\n",
            "026 | Block[x, y, z](1 0) =   5 | Thread[x, y] (2 0 ) =   6 BlockDim.x 4 BlockDim.y 1 GridDim.x 2 GridDim.y 2\n",
            "027 | Block[x, y, z](1 0) =   5 | Thread[x, y] (3 0 ) =   7 BlockDim.x 4 BlockDim.y 1 GridDim.x 2 GridDim.y 2\n",
            "032 | Block[x, y, z](1 1) =   7 | Thread[x, y] (0 0 ) =   4 BlockDim.x 4 BlockDim.y 1 GridDim.x 2 GridDim.y 2\n",
            "033 | Block[x, y, z](1 1) =   7 | Thread[x, y] (1 0 ) =   5 BlockDim.x 4 BlockDim.y 1 GridDim.x 2 GridDim.y 2\n",
            "034 | Block[x, y, z](1 1) =   7 | Thread[x, y] (2 0 ) =   6 BlockDim.x 4 BlockDim.y 1 GridDim.x 2 GridDim.y 2\n",
            "035 | Block[x, y, z](1 1) =   7 | Thread[x, y] (3 0 ) =   7 BlockDim.x 4 BlockDim.y 1 GridDim.x 2 GridDim.y 2\n"
          ]
        }
      ]
    }
  ]
}